#  Hadoop MapReduce Project

## Overview

This repository is dedicated to a MapReduce project using Hadoop, focusing on advanced text processing and analysis techniques. The project involves implementing a basic word count application in Hadoop and extending it to include more sophisticated data handling and analysis features.

### Setup

To get started:
1. **Install Java and Hadoop**: Follow the instructions for pseudo-distributed operation on the [Hadoop website](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html).
2. **Test Your Installation**: Use provided examples to ensure Hadoop is set up correctly.
3. **Data Preparation**: Download five books from [Project Gutenberg](https://www.gutenberg.org/ebooks/) and add them to your Hadoop instance.

### Basic Word Count

Develop a word count application in Hadoop. The program should:
- Generate aggregated word counts from the downloaded books.
- Exclude punctuation and be case insensitive.
- Sort and report the 25 most common words.

### Extending Your Application

Enhance your application by:
- Implementing stopword removal.
- Rerunning the application with a list of common English stopwords.
- Reporting the 25 most common words post stopword removal.

### Analysis

This section includes a series of analytical questions based on the application's output, focusing on the effects of stopword removal on system performance and keyspace size.

### Project Execution

Detailed steps for compiling, creating a JAR file, and executing the MapReduce job are provided.

### References

The report includes references and resources for enhancing word count in MapReduce.

### Contribution

Feel free to contribute to this project by suggesting improvements, reporting bugs, or adding new features.

---

Explore the world of Hadoop and MapReduce with hands-on experience in data analysis and optimization! ðŸš€

